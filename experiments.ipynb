{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Experiments for ETIC\n",
    "\n",
    "Lang Liu\n",
    "\n",
    "03/03/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import ot\n",
    "import seaborn as sns\n",
    "\n",
    "from ind_tests import AdaptiveETICTest, ETICTest, HSICTest, L1Test, MutualInfoTest\n",
    "from ind_tests import get_random_feature\n",
    "from sklearn.decomposition import PCA\n",
    "from urllib.request import urlretrieve\n",
    "from utils import generate_data, load_data, median_dist\n",
    "\n",
    "COLORS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['legend.fontsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['lines.markersize'] = 7.5\n",
    "\n",
    "LINESTYLE = ['-', '--', '-.', (0, (1, 1)), '-', '--']\n",
    "MARKER = ['8', 's', '', '', '^', '8']\n",
    "TEST = ['ETIC', 'ETIC-RF', 'HSIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPERMS = 2  # number of permutations in the permutation test\n",
    "ALPHA = 0.05  # significance level\n",
    "NREPS = 2  # number of repetitions\n",
    "SYN_REGS = [0.25, 0.5, 1.0, 2.0, 4.0]  # hyperparameters in the synthetic examples\n",
    "BON_REGS = [0.25, 4.0]  # hyperparameters for the Bonferroni-type adaptive ETIC test\n",
    "REAL_REGS = np.round(np.linspace(0.25, 4, 12), 2)  # hyperparameters in the real example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_mat(x, y, weight=1.0):\n",
    "    return ot.dist(x, y) / weight\n",
    "\n",
    "\n",
    "def gram_mat(x, y, kpar):\n",
    "    return np.exp(-ot.dist(x, y)/kpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_etic(X, Y, regs, cost_mat):\n",
    "    xmed, ymed = median_dist(X, Y)\n",
    "    xcost = cost_mat(X, X, regs[0]*xmed)\n",
    "    ycost = cost_mat(Y, Y, regs[1]*ymed)\n",
    "    mytest = ETICTest(1.0)\n",
    "    decision = mytest.decision(xcost, ycost, ALPHA, NPERMS)\n",
    "    return decision\n",
    "\n",
    "\n",
    "# Adaptive ETIC\n",
    "def run_aetic_test(X, Y, regs, cost_mat):\n",
    "    xmed, ymed = median_dist(X, Y)\n",
    "    xcost = cost_mat(X, X, xmed)\n",
    "    ycost = cost_mat(Y, Y, ymed)\n",
    "    mytest = AdaptiveETICTest(regs)\n",
    "    decision = mytest.decision(xcost, ycost, ALPHA, NPERMS)\n",
    "    return decision\n",
    "\n",
    "\n",
    "# Bonferroni adaptive ETIC\n",
    "def run_baetic_test(X, Y, regs, cost_mat):\n",
    "    ntests = len(regs)**2\n",
    "    xmed, ymed = median_dist(X, Y)\n",
    "    xcost = cost_mat(X, X, xmed)\n",
    "    ycost = cost_mat(Y, Y, ymed)\n",
    "    mytest = ETICTest(1.0)\n",
    "    decision = []\n",
    "    for xeps in regs:\n",
    "        for yeps in regs:\n",
    "            decision.append(mytest.decision(\n",
    "                xcost/xeps, ycost/yeps, ALPHA/ntests, NPERMS))\n",
    "    return np.max(decision)\n",
    "\n",
    "\n",
    "def run_eticrf(X, Y, regs, nfeat, npc=None):\n",
    "    if npc:\n",
    "        pca = PCA(n_components=npc)\n",
    "        X = pca.fit_transform(X)\n",
    "        Y = pca.fit_transform(Y)\n",
    "    xmed, ymed = median_dist(X, Y)\n",
    "    xfeat = get_random_feature(X, nfeat, regs[0]*xmed)\n",
    "    yfeat = get_random_feature(Y, nfeat, regs[1]*ymed)\n",
    "    mytest = ETICTest(1.0)\n",
    "    decision = mytest.decision_with_rf(xfeat, yfeat, ALPHA, NPERMS)\n",
    "    return decision\n",
    "\n",
    "\n",
    "def run_hsic(X, Y, gram_mat, kpars):\n",
    "    xkpar, ykpar = median_dist(X, Y)\n",
    "    xgram = gram_mat(X, X, xkpar*kpars[0])\n",
    "    ygram = gram_mat(Y, Y, ykpar*kpars[1])\n",
    "    mytest = HSICTest()\n",
    "    decision = mytest.decision(xgram, ygram, ALPHA, NPERMS)\n",
    "    return decision\n",
    "\n",
    "\n",
    "def run_info(X, Y, nparts, test):\n",
    "    if test == 'l1':\n",
    "        mytest = L1Test()\n",
    "    elif test == 'mi':\n",
    "        mytest = MutualInfoTest()\n",
    "    decision = mytest.decision(X, Y, ALPHA, NPERMS, nparts=nparts)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_synthtic(x, powers, xlabel, save=False, fname=None):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(powers), sharey=True)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4*len(powers)-1.3)\n",
    "    axes[0].set_ylabel('Power')\n",
    "\n",
    "    for i, power in enumerate(powers):\n",
    "        for j, par in enumerate(SYN_REGS):\n",
    "            axes[i].plot(\n",
    "                x, power[j], label=f'r = {par}',\n",
    "                color=COLORS[j], linestyle=LINESTYLE[j], marker=MARKER[j])\n",
    "            # axes[i].fill_between(x, y-y_std, y+y_std, color=COLORS[0], alpha=0.3)\n",
    "        \n",
    "        axes[i].set_xlabel(xlabel)\n",
    "        axes[i].set_title(TEST[i])\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.tight_layout(rect=[0, 0.08, 1, 1])  # L, B, R, T\n",
    "    lgd = fig.legend(\n",
    "        handles, labels, loc='lower center',\n",
    "        bbox_to_anchor=(0.5, -0.02), ncol=5)\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(fname, bbox_extra_artists=[lgd], bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "def plot_synthetic_aeot(xs, powers, xlabels, label, save=False, fname=None):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(xs), sharey=False)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4*len(xs)+1.0)\n",
    "    axes[0].set_ylabel('Power')\n",
    "    \n",
    "    for i, power in enumerate(powers):\n",
    "        for j, par in enumerate(SYN_REGS):\n",
    "            axes[i].plot(\n",
    "                xs[i], power[j], label=f'r = {par}',\n",
    "                color=COLORS[j], linestyle=LINESTYLE[j], marker=MARKER[j])\n",
    "        \n",
    "        axes[i].plot(\n",
    "            xs[i], power[j+1], label=label,\n",
    "            color=COLORS[j+1], linestyle=LINESTYLE[j+1], marker=MARKER[j+1])\n",
    "        \n",
    "        axes[i].set_xlabel(xlabels[i])\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.tight_layout(rect=[0, 0.0, 1, 1])  # L, B, R, T\n",
    "    lgd = fig.legend(\n",
    "        handles, labels, loc='center right',\n",
    "        bbox_to_anchor=(1.27, 0.5))\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(fname, bbox_extra_artists=[lgd], bbox_inches='tight')\n",
    "        \n",
    "\n",
    "def plot_synthtic_info(xs, powers, xlabels, labels, save=False, fname=None):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(xs), sharey=False)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4*len(xs)+1)\n",
    "    axes[0].set_ylabel('Power')\n",
    "    \n",
    "    # left plot\n",
    "\n",
    "    for i, power in enumerate(powers):\n",
    "        for j, label in enumerate(labels):\n",
    "            axes[i].plot(\n",
    "                xs[i], power[j], label=label,\n",
    "                color=COLORS[j], linestyle=LINESTYLE[j], marker=MARKER[j])\n",
    "            # axes[i].fill_between(x, y-y_std, y+y_std, color=COLORS[0], alpha=0.3)\n",
    "        \n",
    "        axes[i].set_xlabel(xlabels[i])\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.tight_layout(rect=[0, 0.0, 1, 1])  # L, B, R, T\n",
    "    lgd = fig.legend(\n",
    "        handles, labels, loc='center right',\n",
    "        bbox_to_anchor=(1.24, 0.5))\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(fname, bbox_extra_artists=[lgd], bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "def plot_real(powers, titles, save=False, fname=None):\n",
    "    fig, axes = plt.subplots(1, len(powers), sharey=True)\n",
    "    fig.set_figheight(4.7)\n",
    "    fig.set_figwidth(5*len(powers))\n",
    "    cbar_ax = fig.add_axes([.90, .09, .02, .82])\n",
    "    \n",
    "    vmin = np.min(powers)\n",
    "    vmax = np.max(powers)\n",
    "    for i, (power, title) in enumerate(zip(powers, titles)):\n",
    "        sns.heatmap(power, ax=axes[i], vmin=vmin, vmax=vmax, cbar_ax=cbar_ax)\n",
    "        axes[i].set_title(title)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, .9, 1])\n",
    "    if save:\n",
    "        fig.savefig(fname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Dependency Model\n",
    "\n",
    "Consider a simple linear dependency model, i.e.,\n",
    "$$\n",
    "X \\sim \\mathcal{N}_d(0, I_d) \\quad \\text{and} \\quad Y = X_1 + Z,\n",
    "$$\n",
    "where $X_1$ is the first coordinate of $X$ and $Z \\sim \\mathcal{N}(0, 1)$ is independent of $X$.\n",
    "We fix the sample size $n = 50$ and vary $d \\in \\{1, 2, \\dots, 10\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "ndims = 10\n",
    "dims = range(1, ndims+1)\n",
    "dist = 'normal-linear'\n",
    "par = 0.0\n",
    "nfeat = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run the ETIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic = np.zeros((len(SYN_REGS), ndims, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, d in enumerate(dims):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            etic[i, j, rep] = run_etic(X, Y, [reg, reg], cost_mat)\n",
    "\n",
    "etic = np.mean(etic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the ETIC-RF test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic_rf = np.zeros((len(SYN_REGS), ndims, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, d in enumerate(dims):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            etic_rf[i, j, rep] = run_eticrf(X, Y, [reg, reg], nfeat)\n",
    "\n",
    "etic_rf = np.mean(etic_rf, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the HSIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsic = np.zeros((len(SYN_REGS), ndims, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, d in enumerate(dims):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            hsic[i, j, rep] = run_hsic(X, Y, gram_mat, [reg, reg])\n",
    "\n",
    "hsic = np.mean(hsic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results (cf. Figure 1 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthtic(dims, [etic, etic_rf, hsic], 'Dimension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also run the two adaptive ETIC tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aetic = np.zeros((1, ndims, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, d in enumerate(dims):\n",
    "        X, Y = generate_data(n, [d, 1], dist, par)\n",
    "        aetic[0, j, rep] = run_etic(X, Y, SYN_REGS, cost_mat)\n",
    "\n",
    "aetic = np.mean(aetic, axis=2)\n",
    "linear_aetic = np.concatenate([etic, aetic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baetic = np.zeros((1, ndims, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, d in enumerate(dims):\n",
    "        X, Y = generate_data(n, [d, 1], dist, par)\n",
    "        baetic[0, j, rep] = run_etic(X, Y, BON_REGS, cost_mat)\n",
    "\n",
    "baetic = np.mean(baetic, axis=2)\n",
    "linear_baetic = np.concatenate([etic, baetic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Sign Model\n",
    "\n",
    "Consider a Gaussian sign model, i.e.,\n",
    "$$\n",
    "X \\sim \\mathcal{N}_d(0, I_d) \\quad \\text{and} \\quad Y = \\lvert Z \\rvert \\prod_{i=1}^d \\text{sgn}(X_i),\n",
    "$$\n",
    "where $\\text{sgn}(\\cdot)$ is the sign function and $Z \\sim \\mathcal{N}(0, 1)$ is independent of $X$.\n",
    "We fix $d = 3$ and vary $n \\in [100, 500]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "nsizes = 10\n",
    "ns = np.linspace(100, 500, nsizes, dtype=int)\n",
    "dist = 'normal-sign'\n",
    "par = 0.0\n",
    "nfeat = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run the ETIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic = np.zeros((len(SYN_REGS), nsizes, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, n in enumerate(ns):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            etic[i, j, rep] = run_etic(X, Y, [reg, reg], cost_mat)\n",
    "\n",
    "etic = np.mean(etic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the ETIC-RF test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic_rf = np.zeros((len(SYN_REGS), nsizes, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, n in enumerate(ns):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            etic_rf[i, j, rep] = run_eticrf(X, Y, [reg, reg], nfeat)\n",
    "\n",
    "etic_rf = np.mean(etic_rf, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the HSIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsic = np.zeros((len(SYN_REGS), nsizes, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, n in enumerate(ns):\n",
    "            X, Y = generate_data(n, [d, 1], dist, par)\n",
    "            hsic[i, j, rep] = run_hsic(X, Y, gram_mat, [reg, reg])\n",
    "\n",
    "hsic = np.mean(hsic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results (cf. Figure 2 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthtic(ns, [etic, etic_rf, hsic], 'Sample size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also run the $L_1$ test and the Log-likelihood test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparts = 3\n",
    "\n",
    "l1 = np.zeros((1, nsizes, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, n in enumerate(ns):\n",
    "        X, Y = generate_data(n, [d, 1], dist, par)\n",
    "        l1[0, j, rep] = run_info(X, Y, nparts, 'l1')\n",
    "l1 = np.mean(l1, axis=2)\n",
    "\n",
    "\n",
    "mi = np.zeros((1, nsizes, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, n in enumerate(ns):\n",
    "        X, Y = generate_data(n, [d, 1], dist, par)\n",
    "        mi[0, j, rep] = run_info(X, Y, nparts, 'mi')\n",
    "mi = np.mean(mi, axis=2)\n",
    "\n",
    "sign = np.concatenate([etic[0:1], etic_rf[0:1], l1, mi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subspace Dependency Model\n",
    "\n",
    "We construct our data by the following steps:\n",
    "\n",
    "1. Generate $n$ i.i.d. copies of two random variables following independently $0.5\\mathcal{N}(0.98, 0.04) + 0.5\\mathcal{N}(-0.98, 0.04)$.\n",
    "2. Mix the two random variables by a rotation matrix parametrized by $\\theta \\in [0, \\pi/4]$.\n",
    "3. Append $\\mathcal{N}_{d-1}(0, I_{d-1})$ to each of the two mixtures.\n",
    "4. Multiply each vector by an independent random $d$-dimensional orthogonal matrix.\n",
    "\n",
    "We fix $n = 64$, $d = 2$ and vary $\\theta \\in [0, \\pi/4]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64\n",
    "d = 2\n",
    "npars = 12\n",
    "pars = np.linspace(0, 1, npars)\n",
    "dist = 'g'\n",
    "nfeat = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run the ETIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic = np.zeros((len(SYN_REGS), npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, par in enumerate(pars*np.pi/4):\n",
    "            X, Y = generate_data(n, [d, d], dist, par)\n",
    "            etic[i, j, rep] = run_etic(X, Y, [reg, reg], cost_mat)\n",
    "\n",
    "etic = np.mean(etic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the ETIC-RF test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic_rf = np.zeros((len(SYN_REGS), npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, par in enumerate(pars*np.pi/4):\n",
    "            X, Y = generate_data(n, [d, d], dist, par)\n",
    "            etic_rf[i, j, rep] = run_eticrf(X, Y, [reg, reg], nfeat)\n",
    "\n",
    "etic_rf = np.mean(etic_rf, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the HSIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsic = np.zeros((len(SYN_REGS), npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for i, reg in enumerate(SYN_REGS):\n",
    "        for j, par in enumerate(pars*np.pi/4):\n",
    "            X, Y = generate_data(n, [d, d], dist, par)\n",
    "            hsic[i, j, rep] = run_hsic(X, Y, gram_mat, [reg, reg])\n",
    "\n",
    "hsic = np.mean(hsic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results (cf. Figure 3 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthtic(pars, [etic, etic_rf, hsic], r'$\\theta$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also run the two adaptive ETIC tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aetic = np.zeros((1, npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, par in enumerate(pars*np.pi/4):\n",
    "        X, Y = generate_data(n, [d, d], dist, par)\n",
    "        aetic[0, j, rep] = run_etic(X, Y, SYN_REGS, cost_mat)\n",
    "\n",
    "aetic = np.mean(aetic, axis=2)\n",
    "subspace_aetic = np.concatenate([etic, aetic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baetic = np.zeros((1, npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, par in enumerate(pars*np.pi/4):\n",
    "        X, Y = generate_data(n, [d, d], dist, par)\n",
    "        baetic[0, j, rep] = run_etic(X, Y, BON_REGS, cost_mat)\n",
    "\n",
    "baetic = np.mean(baetic, axis=2)\n",
    "subspace_baetic = np.concatenate([etic, baetic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results of the adative ETIC test (cf. Figure 7 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_aeot(\n",
    "    [dims, pars], [linear_aetic, subspace_aetic],\n",
    "    ['Dimension', r'$\\theta$'], 'Adaptive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results of the Bonferroni adative ETIC test (cf. Figure 8 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthetic_aeot(\n",
    "    [dims, pars], [linear_baetic, subspace_baetic],\n",
    "    ['Dimension', r'$\\theta$'], 'Bonferroni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we run the $L_1$ test and the Log-likelihood test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparts = 3\n",
    "\n",
    "l1 = np.zeros((1, npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, par in enumerate(pars*np.pi/4):\n",
    "        X, Y = generate_data(n, [d, d], dist, par)\n",
    "        l1[0, j, rep] = run_info(X, Y, nparts, 'l1')\n",
    "l1 = np.mean(l1, axis=2)\n",
    "\n",
    "mi = np.zeros((1, npars, NREPS))\n",
    "for rep in range(NREPS):\n",
    "    npr.seed(rep)\n",
    "    for j, par in enumerate(pars*np.pi/4):\n",
    "        X, Y = generate_data(n, [d, d], dist, par)\n",
    "        mi[0, j, rep] = run_info(X, Y, nparts, 'mi')\n",
    "mi = np.mean(mi, axis=2)\n",
    "\n",
    "subspace = np.concatenate([etic[0:1], etic_rf[0:1], l1, mi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results of the baseline tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_synthtic_info([ns, pars], [sign, subspace], ['Sample size', r'$\\theta$'], ['ETIC', 'ETIC-RF', 'L1', 'Log-lik'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilingual Text\n",
    "\n",
    "We now investigate the performance of the ETIC test on bilingual data.\n",
    "Our dataset is taken from the parallel European Parliament corpus [1] which consists of a large number of documents of the same content in different languages.\n",
    "\n",
    "We randomly select $n = 64$ English documents and a paragraph in each document from the corpus.\n",
    "We then\n",
    "\n",
    "1. pair each paragraph with the corresponding paragraph in French to form the dependent sample;\n",
    "2. pair each paragraph with a random paragraph in the same document in French to form the partially dependent sample;\n",
    "3. pair each paragraph with a random paragraph in French to form the independent sample.\n",
    "\n",
    "Wew use LaBSE [2] to embed all the paragraphs into a common feature embedding space of dimension 768 and provide the embeddings on this [website](https://sites.stat.washington.edu/people/liu16/etic/en-fr-embed.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "urlretrieve('https://sites.stat.washington.edu/people/liu16/etic/en-fr-embed.zip', 'en-fr-embed.zip')\n",
    "# unzip\n",
    "os.system('unzip en-fr-embed.zip')\n",
    "# load\n",
    "data = [load_data(f'en-fr-embed/size64-part{i}.txt') for i in range(1, NREPS+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run the ETIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etic = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_etic(X, Y, [reg1, reg2], cost_mat) for (X, Y) in data[rep]])\n",
    "            etic[i, j, rep] = res\n",
    "\n",
    "etic = np.mean(etic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the HSIC test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsic = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_hsic(X, Y, gram_mat, [reg1, reg2]) for (X, Y) in data[rep]])\n",
    "            hsic[i, j, rep] = res\n",
    "\n",
    "hsic = np.mean(hsic, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results on the dependent sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ETIC')\n",
    "print(etic[:, :, 0])\n",
    "print('HSIC')\n",
    "print(hsic[:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results on the independent sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ETIC')\n",
    "print(etic[:, :, 2])\n",
    "print('HSIC')\n",
    "print(hsic[:, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results on the partially dependent sample (cf. Figure 4 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real([etic[:, :, 1], hsic[:, :, 1]], ['ETIC', 'HSIC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ETIC-RF test, we reduce the dimension by the principal component analysis before we run the test.\n",
    "We experiment with different numbers of random features $p$ and principal components $d'$ and examine their effect on the performance of the ETIC-RF test.\n",
    "\n",
    "We fix $p = 700$ and consider $d' \\in \\{10 ,20\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = 700\n",
    "\n",
    "npc = 10\n",
    "etic_rf_1 = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_eticrf(X, Y, [reg1, reg2], nfeat, npc) for (X, Y) in data[rep]])\n",
    "            etic_rf_1[i, j, rep] = res\n",
    "\n",
    "etic_rf_1 = np.mean(etic_rf_1, axis=2)\n",
    "\n",
    "npc = 20\n",
    "etic_rf_2 = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_eticrf(X, Y, [reg1, reg2], nfeat, npc) for (X, Y) in data[rep]])\n",
    "            etic_rf_2[i, j, rep] = res\n",
    "\n",
    "etic_rf_2 = np.mean(etic_rf_2, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results on the partially dependent sample (cf. Figure 5 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real([etic_rf_1[:, :, 1], etic_rf_2[:, :, 1]], ['d\\' = 10', 'd\\' = 20'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix $d' = 10$ and consider $p \\in \\{700, 1500\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npc = 10\n",
    "\n",
    "nfeat = 700\n",
    "etic_rf_1 = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_eticrf(X, Y, [reg1, reg2], nfeat, npc) for (X, Y) in data[rep]])\n",
    "            etic_rf_1[i, j, rep] = res\n",
    "\n",
    "etic_rf_1 = np.mean(etic_rf_1, axis=2)\n",
    "\n",
    "nfeat = 1500\n",
    "etic_rf_2 = np.zeros((len(REAL_REGS), len(REAL_REGS), NREPS, len(data[0])))\n",
    "for rep in range(NREPS):\n",
    "    for i, reg1 in enumerate(REAL_REGS):\n",
    "        for j, reg2 in enumerate(REAL_REGS):\n",
    "            npr.seed(rep)\n",
    "            res = np.array([run_eticrf(X, Y, [reg1, reg2], nfeat, npc) for (X, Y) in data[rep]])\n",
    "            etic_rf_2[i, j, rep] = res\n",
    "\n",
    "etic_rf_2 = np.mean(etic_rf_2, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results on the partially dependent sample (cf. Figure 6 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real([etic_rf_1[:, :, 1], etic_rf_2[:, :, 1]], ['p = 700', 'p = 1500'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] P. Koehn. Europarl: A parallel corpus for statistical machine translation. In *Proceedings of Machine Translation Summit*, 2005.\n",
    "\n",
    "[2] F. Feng, Y. Yang, D. CCer, N. Arivazhagan, and W. Wang. Language-agnostic BERT sentence em-\n",
    "bedding. *ArXiv Preprint*, 2020."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fd16c4eefd74fc01a7a399d01ce10a31c6e1d6b88bf29ea6cb4b862885af934"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('eot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
